#FIRST SECTION: Processing 16S amplicon sequences using mothur
    
#Purpose: To use mothur to process paired-end 16S rRNA gene sequences from the research paper "Shifts in the swine nasal microbiota following Bordetella bronchiseptica challenge in a longitudinal study".

#Files needed:
#*.fastq files from Bioproject PRJNA525911

#Open mothur, then input the following commands (output files are listed directly below each command):

#Create directory of fastq files and file names
make.file(inputdir=<directory path>, type=fastq, prefix=SRD129BB)
#prefix can be whatever name you want to call the files. We called it SRD129BB
#Output: 
#SRD129BB.files

#Check SRD129BB.files to make sure the text file has the correct three columns (sample name, R1*.fastq, R2*.fastq). If the three columns are not labeled correctly, edit as appropriate using command-line tools, text editor, etc. You will also need to replace "-" with "_".

#Combine reads and data from all samples
make.contigs(file=SRD129BB.files, processors=39)
#Output:
#SRD129BB.trim.contigs.fasta
#SRD129BB.scrap.contigs.fasta
#SRD129BB.contigs.report
#SRD129BB.contigs.groups

#Summarize SRD129BB.trim.contigs.fasta
summary.seqs(fasta=SRD129BB.trim.contigs.fasta)
#Output:
#SRD129BB.trim.contigs.summary

#Remove sequences with ambiguous bases, anything longer than 275bp, 6 homopolymeric tracts
screen.seqs(fasta=SRD129BB.trim.contigs.fasta, summary=SRD129BB.trim.contigs.summary, maxambig=0, maxlength=275, maxhomop=6, group=SRD129BB.contigs.groups)
#Output:
#SRD129BB.contigs.pick.groups
#SRD129BB.trim.contigs.good.summary
#SRD129BB.trim.contigs.good.fasta
#SRD129BB.trim.contigs.bad.accnos
#SRD129BB.contigs.good.groups

#Merge duplicate sequences
unique.seqs(fasta=current)
#Output:
#SRD129BB.trim.contigs.good.names
#SRD129BB.trim.contigs.good.unique.fasta

#Generate table with names of unique sequences and names of the groups
count.seqs(name=current, group=current)
#Output: 
#SRD129BB.trim.contigs.good.count_table

#Summarize SRD129BB.trim.contigs.good.count_table, SRD129BB.trim.contigs.good.unique.fasta
summary.seqs(count=current, fasta=current, processors=39)
#Output: 
#SRD129BB.trim.contigs.good.unique.summary

#Download or import silva full length sequences and taxonomy references from https://mothur.org/wiki/Silva_reference_files
#Unzip tar.gz file and use the silva*.align file for pcr.seqs command
#I used silva version 132, which was the latest version at the time.
pcr.seqs(fasta=silva.seed_v132.align, start=11894, end=25319, keepdots=F)
#Output: 
#silva.nr_v132.pcr.align
#silva.nr_v132.bad.accnos

#Rename to a shorter file name
rename.file(input=silva.seed_v132.pcr.align, new=silva.v4.fasta)

summary.seqs(fasta=silva.v4.fasta)
#Output: silva.v4.summary

#Align sequences to reference sequences
align.seqs(fasta=SRD129BB.trim.contigs.good.unique.fasta, reference=silva.v4.fasta, flip=T)
#Output:
#SRD129BB.trim.contigs.good.unique.align
#SRD129BB.trim.contigs.good.unique.align.report
#SRD129BB.trim.contigs.good.unique.flip.accnos

summary.seqs(fasta=current, count=SRD129BB.trim.contigs.good.count_table)
#Output:
#SRD129BB.trim.contigs.good.unique.good.summary

#Keep sequences that start at or before position 1968 and end at or after position 11550
screen.seqs(fasta=SRD129BB.trim.contigs.good.unique.align, count=SRD129BB.trim.contigs.good.count_table, start=1968, end=11550, maxhomop=6)
#Output: 
#SRD129BB.trim.contigs.good.unique.good.align
#SRD129BB.trim.contigs.good.unique.bad.accnos
#SRD129BB.trim.contigs.good.good.count_table

summary.seqs(fasta=current, count=current)
#Output: 
#SRD129BB.trim.contigs.good.unique.good.summary

#Filter out sequences with overhangs at both ends of the region
filter.seqs(fasta=SRD129BB.trim.contigs.good.unique.good.align, vertical=T, trump=.)
#Output:
#SRD129BB.filter
#SRD129BB.trim.contigs.good.unique.good.filter.fasta

unique.seqs(fasta=current, count=SRD129BB.trim.contigs.good.good.count_table)
#Output:
#SRD129BB.trim.contigs.good.unique.good.filter.count_table
#SRD129BB.trim.contigs.good.unique.good.filter.unique.fasta

#Pre-cluster sequences by allowing up to 2 differences between sequences.
pre.cluster(fasta=current, count=current, diffs=2)
#Output:
#SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.fasta
#SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.count_table
#SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.SRD129_P*_*_D*.map

#Remove chimeric sequences
chimera.vsearch(fasta=SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.fasta, count=SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.count_table, dereplicate=t)
#Output:
#SRD129BB.trim.contigs.good.unique.good.filter.SRD129_P*_*_D*.count_table
#SRD129BB.trim.contigs.good.unique.good.filter.unique.SRD129_P*_*_D*.fasta
#SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.count_table
#SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.chimeras
#SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.accnos

#Remove chimeric sequences from fasta file
remove.seqs(fasta=current, accnos=current)
#Output: 
#SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.pick.fasta

summary.seqs(fasta=current, count=current)
#Output:
#SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.pick.summary

#Classify sequences
classify.seqs(fasta=SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.pick.fasta, count=SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.count_table, reference=silva.v4.fasta, taxonomy=silva.nr_v132.tax, cutoff=80)
#Output:
#SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.pick.nr_v132.wang.taxonomy
#SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.pick.nr_v132.wang.tax.summary

#Remove undesirable sequences with specific taxon labels
remove.lineage(fasta=current, count=current, taxonomy=current, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota)
#Output:
#SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.pick.nr_v132.wang.pick.taxonomy
#SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.pick.nr_v132.wang.accnos
#SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.fasta
#SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.pick.count_table

summary.tax(taxonomy=current, count=current)
#Output:
#SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.pick.nr_v132.wang.pick.tax.summary

#Rename the following files to a simpler name
mv SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.fasta SRD129BB.outsingletons.fasta 
mv SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.pick.count_table SRD129BB.outsingletons.count_table

#Take out all the sequences that occur once
split.abund(fasta=SRD129BB.outsingletons.fasta, count=SRD129BB.outsingletons.count_table, cutoff=1, accnos=true)
#Output:
#SRD129BB.outsingletons.rare.count_table
#SRD129BB.outsingletons.abund.count_table
#SRD129BB.outsingletons.rare.accnos
#SRD129BB.outsingletons.abund.accnos
#SRD129BB.outsingletons.rare.fasta
#SRD129BB.outsingletons.abund.fasta

#Calculate uncorrected pairwise distances between aligned DNA sequences
dist.seqs(fasta=SRD129BB.outsingletons.abund.fasta, cutoff=0.03)
#Output:
#SRD129BB.outsingletons.abund.dist

#Assign sequences to OTUs
cluster(column=current, count=SRD129BB.outsingletons.abund.count_table)
#Output:
#SRD129BB.outsingletons.abund.opti_mcc.list
#SRD129BB.outsingletons.abund.opti_mcc.steps
#SRD129BB.outsingletons.abund.opti_mcc.sensspec

#Determine number of sequences in each OTU from each sample
make.shared(list=current, count=SRD129BB.outsingletons.abund.count_table, label=0.03)
#Output:
#SRD129BB.outsingletons.abund.opti_mcc.shared

#Identify taxonomies for each OTU
classify.otu(list=SRD129BB.outsingletons.abund.opti_mcc.list, count=SRD129BB.outsingletons.abund.count_table, taxonomy=SRD129BB.trim.contigs.good.unique.good.filter.unique.precluster.pick.nr_v132.wang.pick.taxonomy, label=0.03)
#Output:
#SRD129BB.outsingletons.abund.opti_mcc.0.03.cons.taxonomy
#SRD129BB.outsingletons.abund.opti_mcc.0.03.cons.tax.summary

#Files of importance
#count=SRD129BB.outsingletons.abund.count_table
#shared=SRD129BB.outsingletons.abund.opti_mcc.shared 
#constaxonomy=SRD129BB.outsingletons.abund.opti_mcc.0.03.cons.taxonomy

#Determine number of sequences in each sample
count.groups(shared=SRD129BB.outsingletons.abund.opti_mcc.shared)
#Output:
#SRD129BB.outsingletons.abund.opti_mcc.count.summary

#Normalize data
sub.sample(shared=SRD129BB.outsingletons.abund.opti_mcc.shared, size=2000)
#Output:
#SRD129BB.outsingletons.abund.opti_mcc.0.03.subsample.shared

#See number of sequences in each sample after subsampling as well as number of sequences total
count.groups(shared=current)
#Output:
#SRD129BB.outsingletons.abund.opti_mcc.0.03.subsample.count.summary

#Determine final number of sequences
summary.seqs(fasta=SRD129BB.outsingletons.abund.fasta)
#Output:
#SRD129BB.outsingletons.abund.summary

#Check sequence quality using fastQC and multiQC, and work within a new directory
#Download fastqc to your computer and enter in the terminal the following commands:

fastqc
mkdir fastqc
fastqc *.fastq -o fastqc

#Output:
#*fastqc.zip
#*fastqc.html

#Copy all nasal fastqc files to the new directory. MultiQC for nasal wash
multiqc .
#Output:
SRD129BB_nasal_multiqc_data
SRD129BB_nasal_multiqc.html